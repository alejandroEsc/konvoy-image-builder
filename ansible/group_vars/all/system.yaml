# TODO: use overrides to set these
kubernetes_semver: "v{{ kubernetes_version }}"

kubernetes_rpm_repository_url: "https://packages.d2iq.com/konvoy/rpm/stable/centos/7/x86_64"
kubernetes_rpm_gpg_key_url: "https://packages.d2iq.com/konvoy/rpm-gpg-pub-key"

kubernetes_rpm_suse_repository_url: "https://packages.d2iq.com/konvoy/rpm/stable/suse/{{ ansible_distribution_major_version|int }}/x86_64"
kubernetes_rpm_suse_gpg_key_url: "https://packages.d2iq.com/konvoy/rpm-gpg-pub-key"

# containerd package
# Appstream is enabled by default in rhel8, so install the package from local repositories in that case
docker_rpm_container_selinux_package_url: "{{ 'http://mirror.centos.org/centos/7/extras/x86_64/Packages/container-selinux-2.107-3.el7.noarch.rpm' if ansible_distribution_major_version|int < 8 else 'container-selinux' }}"
docker_rpm_container_selinux_gpg_key_url: "http://mirror.centos.org/centos/RPM-GPG-KEY-CentOS-7"

docker_rpm_repository_url_upstream_mirror: "https://packages.d2iq.com/download.docker.com/linux/centos/7/x86_64/stable"
docker_rpm_repository_url: "https://packages.d2iq.com/konvoy/stable/linux/centos/{{ ansible_distribution_major_version|int }}/x86_64"
docker_rpm_gpg_key_url: "{{ docker_rpm_repository_url }}/gpg.asc"


docker_rpm_suse_repository_url: "https://packages.d2iq.com/konvoy/stable/linux/opensuse/leap/{{ ansible_distribution_major_version|int }}/x86_64"
docker_rpm_suse_gpg_key_url: "{{ docker_rpm_suse_repository_url }}/gpg.asc"

# nvidia package
nvidia_cuda_version: "460"
libnvidia_container_rpm_repository_package_url: "https://nvidia.github.io/libnvidia-container/centos7/x86_64"
libnvidia_container_deb_repository_url: "https://nvidia.github.io/libnvidia-container/ubuntu16.04/amd64"
libnvidia_container_gpg_key_url: "https://nvidia.github.io/libnvidia-container/gpgkey"
nvidia_container_runtime_rpm_repository_package_url: "https://nvidia.github.io/nvidia-container-runtime/centos7/x86_64"
nvidia_container_runtime_deb_package_url: "https://nvidia.github.io/nvidia-container-runtime/ubuntu16.04/amd64"
nvidia_container_runtime_gpg_key_url: "https://nvidia.github.io/nvidia-container-runtime/gpgkey"
nvidia_driver_rpm_repository_package_url: http://developer.download.nvidia.com/compute/cuda/repos/rhel{{ ansible_distribution_major_version|int }}/x86_64/
nvidia_driver_rpm_gpg_key_url: http://developer.download.nvidia.com/compute/cuda/repos/rhel{{ ansible_distribution_major_version|int }}/x86_64/7fa2af80.pub
# On Centos7 installs `nvidia-driver` with dkms for kernel
nvidia_driver_rpm_package_name: "nvidia-driver-latest-dkms"
nvidia_driver_rpm_package_version: "460.73.01-1.el7.x86_64"
# On Centos8 installs `nvidia-driver` module with given version
nvidia_driver_dnf_module_name: "nvidia-driver"
nvidia_driver_dnf_module_version: "{{nvidia_cuda_version}}-dkms"

# the nvidia-container-runtime package no longer exists for rhel8 so we must install the last available version
nvidia_container_runtime_package: "{{ 'nvidia-container-runtime' if ansible_distribution_major_version|int < 8 else 'nvidia-container-runtime-3.4.0-1.x86_64' }}"

kubernetes_full_version: "{{ kubernetes_version }}{{ kubernetes_build_meta }}"
package_versions:
  enable_repository_installation: "{{ (spec.osPackages.enableAdditionalRepositories if spec.osPackages is defined else true)|default(true)|bool }}"
  # the version may contain d2iq specific suffix, remove it when downloading packages
  kubernetes_rpm: "{{ kubernetes_version }}-0"
  kubernetes_deb: "{{ kubernetes_version }}-00"
  kubenode: "{{ kubernetes_version }}"
  containerd_minor_version: "{{ containerd_version[:3] }}"

default_image_registry: ""

fips:
  enabled: false

proxy_env:
  HTTPS_PROXY: "{{ https_proxy | default('') }}"
  https_proxy: "{{ https_proxy | default('') }}"
  HTTP_PROXY: "{{ http_proxy | default('') }}"
  http_proxy: "{{ http_proxy | default('') }}"
  NO_PROXY: "{{ no_proxy | default('') }}"
  no_proxy: "{{ no_proxy | default('') }}"

python_env:
  PYTHONPATH: "{{ python_path }}"

default_env: "{{ proxy_env | combine(python_env) }}"

##### Preflight #########
kubernetes_regexed_version: "{{ kubernetes_version | regex_replace('\\+.+$', '') }}"
configured_ansible_distribution: "{{ node_os_distribution[node_pool] if node_pool is defined and node_os_distribution[node_pool] is defined and node_os_distribution[node_pool] != '' else ansible_distribution }}"

system_default_path_env: "/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"
system_path_env: "{{ ansible_env.PATH if ansible_env is defined and ansible_env.PATH is defined else '' }}:{{ system_default_path_env }}"
combined_env: "{{ proxy_env | combine({'PATH': system_path_env}) }}"

control_plane_hostnames: "{{ groups['control-plane'] | map('extract', hostvars, ['ansible_hostname']) | select('defined') | list }}"
worker_hostnames: "{{ groups['node'] | map('extract', hostvars, ['ansible_hostname']) | select('defined') | list }}"

# control-plane
apiserver_endpoint: "{{ control_plane_endpoint }}"
external_apiserver_address: "{{ apiserver_endpoint.split(':')[0] }}"
external_apiserver_port: "{{ apiserver_endpoint.split(':')[1] }}"

# kube-apiserver additional arguments:
apiserver:
  secure_port: "{{ 6443 if cloud_provider is defined and cloud_provider == 'gcp' else external_apiserver_port }}"
  # Ideally set to 4096 for a production environment
  target_ram_mb: >-
    {% if targetRamMB is defined %}
    {{-targetRamMB-}}
    {% elif kubernetes_regexed_version < '1.19' %}
    {{-'2048'-}}
    {% else %}
    {{-''-}}
    {% endif %}
  max_requests_inflight: 1200
  max_mutating_requests_inflight: 400
##### Preflight #########
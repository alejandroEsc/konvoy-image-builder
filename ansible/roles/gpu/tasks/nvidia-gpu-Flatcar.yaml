---
# build kernel modules
- name: load loop modules
  command: modprobe -d / -a loop i2c_core ipmi_msghandler

- name: prepare loop modules
  command: echo -e "loop\ni2c_core\nipmi_msghandler" | tee /etc/modules-load.d/driver.conf

- name: pull driver build image
  command: "docker pull nvcr.io/nvidia/driver:460.73.01-5.10.32-flatcar"

# Note, this has be to run privileged as the driver module has to be loaded (briefly).
- name: run the build
  command: docker run -d --rm --privileged --pid=host -v /run/nvidia:/run/nvidia:shared -v /tmp/nvidia:/var/log -v /usr/lib64/modules:/usr/lib64/modules -v /opt:/opt --name nvidia-driver nvcr.io/nvidia/driver:460.73.01-5.10.32-flatcar

- name: wait for container being ready
  command: "docker logs --tail 1 nvidia-driver"
  register: build_log
  retries: 720
  delay: 10
  until: "'Done, now waiting for signal' in build_log.stdout"

- name: send signal until build container is gone
  command: "docker kill -s SIGHUP nvidia-driver"

# - name: load nvidia modules
#   command: modprobe -d /opt/ -a nvidia

# build container runtime
- name: create temporary build directory
  ansible.builtin.tempfile:
    state: directory
    suffix: build
  register: build_dir

- name: clone nvidia-container-runtime sources
  command: "git clone --depth 1 --branch v3.5.0 https://gitlab.com/nvidia/container-toolkit/container-runtime.git {{ build_dir.path }}/container-runtime"

- name: pull golang image
  command: "docker pull golang:1.16"

- name: build the nvidia-container-runtime
  command: docker run -i -v  {{ build_dir.path }}/container-runtime:/tmp/container-runtime -w /tmp/container-runtime golang:1.16 "/usr/bin/make" "build"

# install container runtime
# FIXME(tillt): proper copy
- name: copy nvidia-container-runtime
  command: cp {{ build_dir.path }}/container-runtime/nvidia-container-runtime /opt/bin

- name: create nvidia-container-runtime configuration directory
  file:
    path: "/etc/nvidia-container-runtime/"
    state: directory

- name: copy nvidia-container-runtime configuration
  template:
    src: "./etc/nvidia-container-runtime/config.toml"
    dest: "/etc/nvidia-container-runtime/config.toml"

- name: create oci hooks directory
  file:
    path: "/opt/usr/libexec/oci/hooks.d/"
    state: directory

- name: copy oci hook
  template:
    src: "./usr/libexec/oci/hooks.d/oci-nvidia-hook"
    dest: "/opt/usr/libexec/oci/hooks.d/oci-nvidia-hook"
    mode: 0755

- name: create oci hooks configuration directory
  file:
    path: "/opt/usr/share/containers/oci/hooks.d/"
    state: directory

- name: copy oci hook configuration
  template:
    src: "./usr/share/containers/oci/hooks.d/oci-nvidia-hook.json"
    dest: "/opt/usr/share/containers/oci/hooks.d/oci-nvidia-hook.json"


# build libnvidia-container
- name: create temporary build directory
  ansible.builtin.tempfile:
    state: directory
    suffix: build
  register: libnvidia_dir

- name: clone nvidia-container-runtime sources
  command: "git clone --depth 1 --branch v1.4.0 https://gitlab.com/nvidia/container-toolkit/libnvidia-container.git {{ libnvidia_dir.path }}/libnvidia-container"

- name: copy libnvidia build Dockerfile
  copy:
    src: "./Dockerfile.libnvidia"
    dest: "/tmp/Dockerfile.libnvidia"

- name: build the libnvidia-container build image
  command: docker build -f /tmp/Dockerfile.libnvidia --build-arg BUILD_LOCATION={{ libnvidia_dir.path }}/ --tag libnvidia-build ./

- name: build libnvidia-container
  command: docker run -i -v /opt:/opt -v {{ libnvidia_dir.path }}/libnvidia-container:/tmp/libnvidia-container -w /tmp/libnvidia-container libnvidia-build:latest "make"

- name: create /opt/lib directory
  file:
    path: "/opt/lib/"
    state: directory

- name: copy nvidia-container-cli
  command: cp {{ libnvidia_dir.path }}/libnvidia-container/nvidia-container-cli /opt/bin

- name: copy libnvidia-container
  command: cp {{ libnvidia_dir.path }}/libnvidia-container/libnvidia-container.so.1.4.0 /opt/lib

- name: run ldconfig
  command: ldconfig /opt/lib
